---
layout: post
title: 深度学习：参数正规化
description: deep learning基础
category: blog
---

## 7.1 概念

  深度学习中用以减小测试误差，但可能会增加训练误差的策略称为正规化。

  **限制**：有些正规化策略是机器学习模型上添加限制。有些在模型参数上，有些在目标函数上添加额外项。有些限制或惩罚被设计来对特定先验知识编码的，其余的则是为了提高模型泛化能力。

  深度学习中大部分正规化策略都是基于估计正规化，而估计正规化则是通过增加偏置来减少方差。(>比如，神经网络中的神经元都有一个偏置项b<)。 一个估计的正规化的目标是在大幅度减小方差的同时，尽可能小的带来偏置的增加。我们在讨论泛化和过拟合问题时会遇到以下三种情形:

  ![拟合情况](/images/blog/regular1.png)

  + **欠拟合**:实际的正例没有完全被包含在模型预测域。
  + **绝佳**：完全匹配了数据生成过程.(>完全匹配了模拟的函数<)
  + **过拟合**：模型的预测域包含了全部的正例，同时也包含了负例（）。

  正规化的目标就是将模型的**过拟合**情形改善至**绝佳**情形。

  现实情况中，即便是极端复杂的模型也没法完全拟合目标函数(>让神经网络学习人对图像的认知能力，模型已经达到一千层，参数几千万<)，因为大部分情况，我们并不知道目标函数具体是如何映射的。
  这表明设计一个模型的复杂度极高(模型大小，参数等)。而在近些年的实际实验中，我们发现比较好的模型都是正规化处理过后的大模型。

## 7.2 参数规范惩罚

 目前许多正规化方法，如神经网络、线性回归、logistic回归通过在目标函数$J$上加一个参数规范惩罚项 $\Omega(\theta)$ 公式如下:

$$
    \bar{J}(\theta;X,y) = J(\theta;X,y)+\alpha\Omega(\theta)\\\tag {7.1}

 其中 \alpha\epsilon [0,\infty)
$$

其中，更大的 $\alpha$ 对应更强的正规化处理。

 在神经网络中，使用参数规范惩罚，只是对每一层映射转换的权重，不对偏置使用。这是因为权重决定了两个变量如何交互(>神经元如何输出<)，而偏置只作用于单一变量。同时正规化偏置容易引入欠拟合。

**预定义**

+ 向量$w$代表所有需要被规范惩罚的权重
+ 向量 $\theta$代表所有参数，包括$w$和其他非正规化的参数

 尽管每一层使用独立的 $\alpha$参数的惩罚机制效果可能会更好，但是由于计算量太大。实际中所有层使用相同的权重衰减。

### 7.2.1 $L^2$ 参数正规化

最简单最常见的正规惩罚莫过于$L^2$，有时候称为*权重衰减*，同时也称为*岭回归*或者*吉洪诺夫正规*。它是直接在目标函数后面添加一个正规项 $\Omega(\theta)=\frac{1}{2}\|\|w\|\|^2_2$

L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项 $\|\|W\|\|_2$最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0。

回头看式子 $(7.1)$，假设没有偏置参数，因此 $\theta$参数就是$w$,模型目标函数如下:
   $$
    \bar J(w;X,y) =\frac{\alpha}{2}w^Tw+J(w;X,y) \tag{7.2}
   $$

对应的参数梯度如下:

   $$
     \bigtriangledown\bar J(w;X,y)=\alpha w+\bigtriangledown_wJ(w;X,y)
   $$

使用梯度更新权重时:

   $$
    w\leftarrow w-\epsilon(\alpha w+\bigtriangledown_wJ(w;X,y))
   $$

   重写为:

   $$
    w\leftarrow w-(1-\epsilon\alpha)w -\epsilon\bigtriangledown_wJ(w;X,y))
   $$

可以看到新增权重衰减项最终反映出，它通过对每一步的权重向量乘以一个常数因子修改了学习规则。由于 $\epsilon$ ，$\alpha$都是正值，所以它实际是减小了$w$。这就是它被称为**权重衰减**的原因。

 **如何防止过拟合**:更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合刚刚好,而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。

 过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾及每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。

 ![L2正则化示例](/images/blog/regular2.png)

 而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。



### 7.2.2 $L^1$正规化处理

对模型参数$w$上的$L^1$正归化是增加一个惩罚项

$$
  \Omega(\theta) = \|\|w\|\|_1=\sum_i\|w_i\|
$$

完整公式如下：

$$
     \bar J(w;X,y) =\alpha\|\|w\|\|_1+J(w;X,y)
$$

 对上式求梯度得到：

 $$
 \bigtriangledown _w \bar J(w;X,y) = \alpha sign(w)+\bigtriangledown _w J(X,y;w)
 $$

 可以看到，$L^1$正规化对梯度的影响不再与每个$w_i$线性相关，而是一个常量因子。符号只与$w$相关，当w为正时，更新后的w变小。当w为负时，更新后的w变大——因此它的效果就是让w往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合。

 当w为0时怎么办？当w等于0时，\|W\|是不可导的，所以我们只能按照原始的未经正则化的方法去更新w，这就相当于去掉 $\alpha sign(w)$ 这一项，所以我们可以规定$sgn(0)=0$，这样就把w=0的情况也统一进来了

## 7.3 规范惩罚用作约束优化

考虑一个使用了参数规范惩罚正则化的损失函数
$$
  \bar J(\theta;X,y) = J(\theta;X,y)+\alpha \Omega(\theta)
$$
我们可以通过构建一个拉格朗日函数求在约束条件下目标函数的最小值，构建函数即在原始目标函数上添加一些惩罚项。假若我们想要约束条件 $\Omega(\theta)$ 小于一个常量k,可以构建如下拉格朗日函数:
$$
  L(\theta,\alpha;X,y) =J(\theta;X,y)=\alpha(\Omega(\theta)-k)
$$

## 7.4 正则化和受限问题

 机器学习中正则化是十分必要的，许多依赖转置矩阵 $X^TX$ 如线性回归模型，主成分分析(PCA)模型，但是若 $X^TX$ 是奇异的（行列式为0，有无穷个解），就没法实现。当数据在某一些方向上没有方差（所有的值相同）时，矩阵是奇异的。此时需要进行相对应的正则化来保证矩阵是可逆的。

  当线性问题的相关矩阵是可逆时才有封闭解。欠定方程也可能没有封闭解。一个例子是，逻辑回归用于线性可分类问题时，如果权重 $w$ 可获得最佳分类结果，那么$2w$ 也可以，而且使用最大似然框架时，似然度更高。进行迭代优化如使用SGD(随机梯度下降)时将会导致 $w$ 不断增加，而算法不会停止（实际中会产生数值溢出）。

 大多数正则化可以保证迭代方法收敛，比如权重衰减( $L^2$ 正则化)中似然函数梯度等于权重衰减系数时停止。？

## 7.5 数据增强

  理论上来说，数据越多，模型训练得越充分，模型泛化能力越强。但是现实情况是，数据量总是有限的，解决此问题的一个方法是生成一部分的模拟数据。

  这对于分类问题最简单，它需要喂入复杂的高维度数据输入并映射到一个单一分类上。这说明，分类问题主要面临的是对于任意广度的输入其分类结果不变。我们可以简单的生成一个 $(x,y)$ 即可。但是对于很多其他问题，如密度估计问题，很难生成模拟数据，除非已经知道需要解决的密度估计问题。

  数据增强用于特定领域分类问题，如图像识别很有效。（举例）但是切记，转换数据的时候不要改变图像的正确分类。比如不要将手写字识别图像中的`6` 垂直转换成了`9`，`b`水平翻转成了`d`。

  语音识别问题中，网络输入数据中也会注入一些随机噪音干扰，这也是一种数据增强（现实生活中语音环境有噪音）。

  神经网络对噪音鲁棒性并不好，所以我们在可以有一种提升网络性能的方法，即在训练时加入随机干扰。

  由于数据增强的存在，我们在比较机器学习结果时应当考虑数据增强。手工设计的数据通常可以大幅度减少泛化错误（图像分类，如果知道分类结果，制造些类似的图像，然后给分类训练）。所以，在比较机器学习算法时，需要做对照试验，使用相同算法，一组使用没有应用数据增强的输入A，另一组使用应用了数据增强的B，如果A的性能很差，而B的性能很好，那么说明促使模型性能提升的不是算法而是数据。

## 7.6 噪声鲁棒

 对于使用了数据增强的模型，噪音其实等同于在权重分布上增加了惩罚机制。通常，噪音注入比简单的收缩参数(正则化)更有用，尤其是噪音作用于隐藏神经元时，dropout就是专门在方面的进展。

 在RNN中，权重上增加噪声被证明是一种很有效的正则策略（书中论文）。接下来分析下标准前馈神经网络中权重噪音的实际影响。

 在回归问题中，假设损失函数是最小平方误差，如下:

 $$
   J = E_{p(x,y)}[(\bar y(x)-y)^2]
 $$
 假设输入中包含随机扰动 $\epsilon_w \sim N(\epsilon ;0,\eta I)$ ，此时对应的目标函数变成:

 $$
   \bar J_W=E_{p(x,y,\epsilon _w)}[(\bar y_{\epsilon_W}(x)-y)^2] \\
   =E_{p(x,y,\epsilon_W)}[\bar y^2_{\epsilon_W}(x)-2y\bar y_{\epsilon_W}(x)+y^2]
 $$

 若 $\eta$ 很小,最小化 $J$ 等同于最小化 $J$ 外加一个正则项 $\eta E_{p(x,y)}[\|\|\bigtriangledown_W\bar y(x)\|\|^2]$
这种正则项使得模型对参数的轻微扰动不再敏感，此时的最优参数不在使得损失函数最小点而是在最小点附近。

### 7.6.1 在输出目标上注入噪音

 模型的错误分类将导致最大似然框架求得的 $logP(y|x)$ 并不是真正最大点。一种办法是在标签上加入噪音，例如常量 $\theta$ ，此时训练数据集x，其输出被分类到标签y的概率为 $1-\theta$ ，这种方法很容易并入到惩罚函数，而不需要引入噪声数据。这是一种平滑机制，比如标签正则模型基于有k个输出的 *softmax* ，将分类`0`,`1`替换为 $\frac{\theta}{k}$ 和 $1-\frac{k-1}{k}\theta$

## 7.7 多任务学习

 多任务学习可以看做一种从多个模型中抽象出一个汇总模型以提高泛化能力的方法。模型的某个部分的参数在多个任务间共享时，该部分将获得更好的泛化能力。

 下图展示了一个多任务学习方法的常见形式，不同的监督学习任务(对于给定输入X预测输出Y)，共享了相同的输入X，以及一些中间表述层 $h^{shared}$ (捕获参数的一些平均特征)。

 ![](/images/blog/regular3.png)

 通过提升这些共享参数的统计特性（更稳定），可以提高模型泛化能力和泛化边界。与单任务学习相比，其实是按比例增加了共享参数的输入样本。当然前提是，多个模型之间可以共享参数。

 以深度学习的观点来看，这种方法的先验知识是：不同模型的输入数据有些解释了数据变动的参数是在多个任务中共享的。

## 7.8 提前终止

 看一张图：

 ![](/images/blog/regular4.png)

 我们可以看到随着时间或迭代次数的增加，训练误差不断减少，而验证误差最后会逐渐上升，呈U型。验证误差开始上升时，已经出现了过拟合。我们应当在验证误差有段时间没有下降时停止迭代，而不是等到验证误差达到某个极小值时。此策略即提前终止，是正则化策略中最常见，最有效的方法。

 **如何确定何时终止:**

 + 在算法开始之前，先确定训练次数。
 + 在训练过程中定期地运行验证，验证集可以比训练集数据量小。(caffe模型)

**优点**：

 + 几乎不改变算法过程，易于使用
 + 提前终止可以很容易地与其他正则化方法结合使用。

**代价**：

 + 需要不断保存最优模型参数，这是可以接收的，可以直接存放在磁盘上。
 + 需要一个验证数据集，验证数据集不用于训练。

**最大化利用所有数据**

  为了更好的利用所有数据，可以在算法提前终止后再次训练。此时有两种策略

  + 重新初始化模型，在所有数据集上重新训练，但只训练提前终止训练的次数。此时可以增加一些参数，因为数据更多（个人认为，其实是分两步走，第一步是用提前终止找到最优训练次数，第二次再完全训练）

  + 保存第一次训练时的所有参数，并在所有数据上继续训练。此时无法知晓算法何时停止，但是可以观察验证数据集上的平均Loss，当其低于第一次训练的loss时停止。此方法可以避免第一次的重复计算，但是表现一般。

**提前终止的内在机制**：一些论文认为，它能将参数搜索空间限制在较小区间，进而加快模型训练。实际上在使用均方差作为损失函数和梯度下降更新参数的简单线性回归模型中，$L^2$ 正则等同于提前终止。

有图，是否需要解释？

##
